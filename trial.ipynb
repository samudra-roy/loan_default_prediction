{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [5.40345928e+03 1.62124580e+03 1.45752443e+02 3.42410423e+02\n",
      " 8.55048860e-01]\n",
      "Scale: [6.10406486e+03 2.92386446e+03 8.40387142e+01 6.43761414e+01\n",
      " 3.52051569e-01]\n",
      "n_features: 5\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "print(\"Mean:\", scaler.mean_)\n",
    "print(\"Scale:\", scaler.scale_)\n",
    "print(\"n_features:\", len(scaler.mean_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Sample: [[0 0 0 0 0 1 1 0 0 0 0 0 1 0]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Personal Projects\\Data\\loan_default_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.92202437]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"loan_default_model.h5\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "numeric_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "sample = np.array([[8000, 2000, 120, 360, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]])\n",
    "sample_scaled = sample.copy()\n",
    "sample_scaled[:, numeric_indices] = scaler.transform(sample[:, numeric_indices])\n",
    "\n",
    "print(\"Scaled Sample:\", sample_scaled)\n",
    "print(\"Prediction:\", model.predict(sample_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Personal Projects\\Data\\loan_default_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Input: [8000, 2000, 120, 360, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0] → Probability: 0.9725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Input: [1000, 0, 250, 360, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0] → Probability: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Personal Projects\\Data\\loan_default_prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"loan_default_model.h5\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "numeric_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "def predict_case(values):\n",
    "    arr = np.array([values], dtype=float)\n",
    "    arr_scaled = arr.copy()\n",
    "    arr_scaled[:, numeric_indices] = scaler.transform(arr[:, numeric_indices])\n",
    "    prob = model.predict(arr_scaled)[0][0]\n",
    "    print(f\"Input: {values} → Probability: {prob:.4f}\")\n",
    "\n",
    "# Case 1: High income, good credit (should repay)\n",
    "predict_case([8000, 2000, 120, 360, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0])\n",
    "\n",
    "# Case 2: Low income, bad credit (should default)\n",
    "predict_case([1000, 0, 250, 360, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eacb1de75b7c2719dc953114e206cacf543bd1dce55483ce6d21051fa4f3328e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
